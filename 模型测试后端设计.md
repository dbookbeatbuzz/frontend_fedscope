# 模型性能测试后端设计（Flask）

本文档定义与当前前端页面（`src/components/ModelTestDialog.vue`）和模拟 API（`src/api/test.js`）完全对齐的后端接口与数据协议。目标是在不改动前端代码的前提下，使用 Flask 提供等价的真实服务。

- 前端关键流转：
  1. 启动测试：返回 `{ jobId, total }`
  2. 订阅流（SSE）：接收 `progress` / `case` / `summary` / `error` 事件
  3. 随时取消：`{ cancelled: true }` 并在流上收到 `error: { message: "cancelled" }`
- 关键请求入参：`modelId`, `sampleCount`, `randomSeed`, `inputType('text'|'image')`
- 关键事件字段：与 `src/api/test.js` 完全一致（见下文“事件数据结构”）

---

## 1. API 设计

基础前缀：`/api/model-tests`

### 1.1 POST /api/model-tests
- 说明：启动一次模型测试任务
- 请求体 JSON：
  - `modelId`: string|number（必填）
  - `sampleCount`: number（默认 50，范围 1-2000）
  - `randomSeed`: number（可选）
  - `inputType`: 'text' | 'image'（默认 'text'）
- 成功返回：`200 OK`
  ```json
  { "jobId": "job_169...", "total": 50 }
  ```
- 失败返回：
  - `400` 参数错误
  - `404` 模型不存在（可选）
  - `500` 内部错误

### 1.2 GET /api/model-tests/:jobId/stream
- 说明：订阅该任务的流式事件（SSE）
- 响应头：`Content-Type: text/event-stream`，`Cache-Control: no-cache`, `X-Accel-Buffering: no`
- 事件：
  - `event: progress`  
    `data: { processed, total, elapsedMs }`
  - `event: case`  
    `data: { caseId, input, label, output, correct, latencyMs }`（其中 `input`：
    - 文本：`{ type: 'text', text }`
    - 图像：二选一方案
      1) URL 方案：`{ type: 'image', url, mime?, width?, height? }`
      2) dataUrl 方案：`{ type: 'image', dataUrl, mime?, width?, height? }`，其中 `dataUrl` 为 `data:<mime>;base64,<b64>` 格式。
    前端已兼容 `url` 与 `dataUrl` 两种字段，推荐在实际数据集场景使用 `dataUrl` 方案，避免额外的文件服务。）
  - `event: summary`  
    `data: { processed, total, accuracy? }`（发送后关闭流）
  - `event: error`  
    `data: { message }`（发送后关闭流）
  - 可选心跳：`event: ping`  
    `data: { t: "2025-09-18T10:00:00Z" }`
- 状态码：
  - `200` 正常建立流
  - `404` job 不存在
  - `410` job 已结束且不可重放（若不实现重放）

### 1.3 POST /api/model-tests/:jobId/cancel
- 说明：取消任务
- 成功返回：`200 OK`
  ```json
  { "cancelled": true }
  ```
- 流端应随后收到：
  - `event: error`  
    `data: { "message": "cancelled" }`
- 失败返回：
  - `404` job 不存在
  - `409` job 已结束（也可幂等返回 `{cancelled: true}`）

### 1.4 GET /api/model-tests/:jobId（可选）
- 说明：查询任务状态
- 成功返回：`200 OK`
  ```json
  {
    "jobId": "...",
    "modelId": "...",
    "status": "pending|running|cancelled|success|error",
    "total": 50,
    "processed": 34,
    "inputType": "image",
    "randomSeed": 42,
    "startedAt": "...",
    "finishedAt": null,
    "error": null
  }
  ```
- 失败返回：`404`

---

## 2. 事件数据结构（与前端 mock 对齐）

### 2.1 progress
```json
{ "processed": 12, "total": 50, "elapsedMs": 600 }
```

### 2.2 case
- 文本输入：
```json
{
  "caseId": "txt_00001",
  "input": { "type": "text", "text": "sample text txt_00001 about cat" },
  "label": "cat",
  "output": {
    "predLabel": "cat",
    "topK": [ {"label":"cat","prob":0.72}, {"label":"dog","prob":0.1}, ... ]
  },
  "correct": true,
  "latencyMs": 37
}
```
- 图像输入：
```json
{
  "caseId": "img_00001",
  "input": { "type": "image", "url": "https://.../128/128", "mime": "image/jpeg", "width": 128, "height": 128 },
  "label": "dog",
  "output": { "predLabel": "car", "topK": [ ... ] },
  "correct": false,
  "latencyMs": 59
}
```
 - 图像输入（dataUrl 方案，推荐用于本地数据集）：
 ```json
 {
   "caseId": "img_00002",
   "input": {
     "type": "image",
     "dataUrl": "data:image/jpeg;base64,/9j/4AAQSkZJRgABAQAAAQABAAD...",
     "mime": "image/jpeg",
     "width": 128,
     "height": 128
   },
   "label": "cat",
   "output": { "predLabel": "cat", "topK": [ ... ] },
   "correct": true,
   "latencyMs": 42
 }
 ```
 说明：`dataUrl` 字段为 base64 编码的图片数据，浏览器 `<img src>` 可直接使用；若图片较大，建议发送缩略图（例如 128x128）以降低 SSE 传输体积，同时保留 `mime/width/height` 元信息。

### 2.3 summary
```json
{ "processed": 50, "total": 50, "accuracy": 0.91 }
```

### 2.4 error
```json
{ "message": "cancelled" }
```

---

## 3. Job 模型与状态机

- Job 字段：
  - `jobId`, `modelId`
  - `status`: `pending|running|cancelled|success|error`
  - `total`, `processed`
  - `inputType`, `randomSeed`
  - `createdAt`, `startedAt`, `finishedAt`
  - `error?`: `{ message }`
  - `workerRef`: 后台线程/任务引用
  - `subscribers`: SSE 订阅集合（每个包含一个写入函数/队列）

- 状态流转：
  - `pending -> running`
  - `running -> success`（发送 `summary` 后清理）
  - `running -> cancelled`（发送 `error: cancelled`）
  - `running -> error`（发送 `error`）

- 存储策略：
  - 开发期：进程内 `dict`
  - 生产：Redis（保存 job 元数据、最近 N 条事件作为重放缓冲）

---

## 4. 流式协议选择

- 首选 SSE（Server-Sent Events）：与浏览器原生 `EventSource` 兼容；接口简单。
- 注意项：
  - 关闭代理缓冲（Nginx `proxy_buffering off`）
  - 设置 `Cache-Control: no-cache`, `X-Accel-Buffering: no`
  - 定期心跳 `ping`，防连接闲置断开
- 重连策略：
  - MVP：不重放；重连后只接收后续事件或直接收到 `410`。
  - 进阶：实现 `Last-Event-ID` 与环形缓冲，支持窗口重放。

---

## 5. Flask 架构与并发

- 目录建议：
```
backend/
  app.py
  blueprints/
    model_tests.py
  services/
    model_test_runner.py
  models/
    job_store.py
  requirements.txt
```

- 并发策略：
  - MVP：`threading.Thread` + `queue.Queue` 生成事件
  - 生产：`Celery`/`RQ` 执行实际推理；Web 进程消费队列向 SSE 推送

- CORS：若前后端不同源，启用 `flask-cors`（允许 `EventSource`）。

- 部署（Gunicorn 示例）：
```
gunicorn backend.app:app \
  --workers 1 \
  --threads 8 \
  --timeout 0 \
  --bind 0.0.0.0:5000
```

- Nginx 反代关键配置：
```
location /api/model-tests/ {
  proxy_pass http://127.0.0.1:5000;
  proxy_http_version 1.1;
  proxy_set_header Connection ""; # 禁止升级为 WS
  proxy_buffering off;            # 关闭缓冲
  chunked_transfer_encoding on;
}
```

---

## 6. 精简实现示例（要点展示）

> 说明：以下为示意代码片段，确保字段与前端 mock 对齐，便于快速落地。

```python
# backend/app.py
from flask import Flask
from flask_cors import CORS
from blueprints.model_tests import bp as model_tests_bp

app = Flask(__name__)
CORS(app, supports_credentials=True)
app.register_blueprint(model_tests_bp, url_prefix='/api/model-tests')
```

```python
# backend/models/job_store.py
import time, threading
from typing import Dict

class Job:
    def __init__(self, job_id, model_id, total, input_type, seed=None):
        self.job_id = job_id
        self.model_id = model_id
        self.total = total
        self.input_type = input_type
        self.random_seed = seed
        self.status = 'pending'
        self.processed = 0
        self.created_at = time.time()
        self.started_at = None
        self.finished_at = None
        self.error = None
        self.cancelled = False
        self.subscribers = set()  # each: callable(event_name:str, payload:dict)
        self.worker = None

jobs: Dict[str, Job] = {}
lock = threading.Lock()
```

```python
# backend/services/model_test_runner.py
import json, random, time, threading, base64
from models.job_store import jobs, lock

LABELS = ['cat','dog','car','tree','house','person']
IMG_URLS = [
  'https://picsum.photos/seed/1/128/128',
  'https://picsum.photos/seed/2/128/128',
  'https://picsum.photos/seed/3/128/128',
]

# 传输模式：'url' 或 'data-url'（推荐在实际数据集使用 'data-url'）
TRANSPORT_MODE = 'data-url'

def bytes_to_data_url(mime: str, content: bytes) -> str:
  b64 = base64.b64encode(content).decode('ascii')
  return f"data:{mime};base64,{b64}"

def _emit(job, event, payload):
    # 复制订阅者，避免遍历中修改
    for cb in list(job.subscribers):
        try:
            cb(event, payload)
        except Exception:
            job.subscribers.discard(cb)

def run_job(job_id):
    with lock:
        job = jobs.get(job_id)
        if not job:
            return
        job.status = 'running'
        job.started_at = time.time()

    rnd = random.Random(job.random_seed)

  def mk_case(case_idx):
        is_image = (job.input_type == 'image')
        label = rnd.choice(LABELS)
        case_id = f"{'img' if is_image else 'txt'}_{case_idx:05d}"
        topk_labels = LABELS[:]
        rnd.shuffle(topk_labels)
        probs = [0]*5
        remain = 1.0
        for i in range(5):
            p = (0.5 + 0.4*rnd.random()) if i==0 else (0.1*rnd.random())
            probs[i] = p
            remain -= p
        s = sum(probs)
        probs = [p/s for p in probs]
        # 若正确，使 top1=label
        correct_prob = max(0.4, min(0.97, 0.78 + 0.1*(rnd.random()*2-1)))
        is_correct = rnd.random() < correct_prob
        topk = [{ 'label': l, 'prob': probs[i] } for i,l in enumerate(topk_labels[:5])]
        if is_correct:
            topk.sort(key=lambda x: x['prob'], reverse=True)
            topk[0]['label'] = label
        pred_label = sorted(topk, key=lambda x: x['prob'], reverse=True)[0]['label']
    latency_ms = int(20 + rnd.random()*60)

    if is_image:
      if TRANSPORT_MODE == 'url':
        input_payload = {
          'type': 'image',
          'url': rnd.choice(IMG_URLS),
          'mime': 'image/jpeg',
          'width': 128,
          'height': 128
        }
      else:
        # 示例：使用占位内容生成 dataUrl。实际中请读取真实图片字节。
        # 例如：with open('/path/to/img.jpg','rb') as f: content = f.read()
        # 这里用简单的 RGB 噪声/单色图占位（请替换为真实数据）
        content = b"\xff\xd8\xff"  # 占位的 JPEG 头片段示例，联调时请替换为真实图片 bytes
        input_payload = {
          'type': 'image',
          'dataUrl': bytes_to_data_url('image/jpeg', content),
          'mime': 'image/jpeg',
          'width': 128,
          'height': 128
        }
    else:
      input_payload = { 'type': 'text', 'text': f'sample text {case_id} about {label}' }
        return {
            'caseId': case_id,
            'input': input_payload,
            'label': label,
            'output': { 'predLabel': pred_label, 'topK': topk },
            'correct': pred_label == label,
            'latencyMs': latency_ms,
        }

    for i in range(1, job.total+1):
        with lock:
            if job.cancelled:
                job.status = 'cancelled'
                job.finished_at = time.time()
                _emit(job, 'error', { 'message': 'cancelled' })
                return
            processed = job.processed
            total = job.total
        _emit(job, 'progress', { 'processed': processed, 'total': total, 'elapsedMs': processed*50 })
        case_payload = mk_case(i)
        _emit(job, 'case', case_payload)
        with lock:
            job.processed += 1
        time.sleep(0.12)

    with lock:
        job.status = 'success'
        job.finished_at = time.time()
        total = job.total
    _emit(job, 'summary', { 'processed': total, 'total': total })
```

> 生产注意：
> - dataUrl 会显著增大 SSE 事件体积，建议：
>   - 发送缩略图（如 128x128）用于前端展示，必要时另行提供下载原图的受限接口；
>   - 控制并发与速率，避免单连接带宽占满；
>   - 配置反向代理超时：`proxy_read_timeout 3600s;`，关闭缓冲已在上文示例中给出。

```python
# backend/blueprints/model_tests.py
from flask import Blueprint, request, Response, stream_with_context, jsonify
import json, time, threading, uuid
from models.job_store import jobs, Job, lock
from services.model_test_runner import run_job

bp = Blueprint('model_tests', __name__)

@bp.post('/')
def start():
    data = request.get_json(force=True, silent=True) or {}
    model_id = data.get('modelId')
    total = int(data.get('sampleCount', 50))
    seed = data.get('randomSeed')
    input_type = data.get('inputType', 'text')
    if not model_id or total < 1 or total > 2000 or input_type not in ('text','image'):
        return jsonify({ 'message': 'bad request' }), 400
    job_id = f"job_{int(time.time()*1000)}_{uuid.uuid4().hex[:6]}"
    job = Job(job_id, model_id, total, input_type, seed)
    with lock:
        jobs[job_id] = job
    t = threading.Thread(target=run_job, args=(job_id,), daemon=True)
    job.worker = t
    t.start()
    return jsonify({ 'jobId': job_id, 'total': total })

@bp.get('/<job_id>/stream')
def stream(job_id):
    with lock:
        job = jobs.get(job_id)
        if not job:
            return jsonify({ 'message': 'job not found' }), 404

    def sse_format(event, payload):
        return f"event: {event}\ndata: {json.dumps(payload, ensure_ascii=False)}\n\n"

    def generate():
        # 订阅：注册一个回调，将事件写到此生成器
        q = []
        cond = threading.Condition()
        def cb(evt, payload):
            with cond:
                q.append((evt, payload))
                cond.notify()
        with lock:
            job.subscribers.add(cb)
        try:
            # 初始触发一次 progress
            with lock:
                q.append(('progress', { 'processed': job.processed, 'total': job.total, 'elapsedMs': job.processed*50 }))
            while True:
                with cond:
                    while not q:
                        cond.wait(timeout=30)
                        # 心跳
                        if not q:
                            yield sse_format('ping', { 't': time.strftime('%Y-%m-%dT%H:%M:%SZ', time.gmtime()) })
                            continue
                    evt, payload = q.pop(0)
                yield sse_format(evt, payload)
                if evt in ('summary', 'error'):
                    break
        finally:
            with lock:
                job.subscribers.discard(cb)
    headers = {
        'Content-Type': 'text/event-stream',
        'Cache-Control': 'no-cache',
        'X-Accel-Buffering': 'no',
        'Connection': 'keep-alive'
    }
    return Response(stream_with_context(generate()), headers=headers)

@bp.post('/<job_id>/cancel')
def cancel(job_id):
    with lock:
        job = jobs.get(job_id)
        if not job:
            return jsonify({ 'message': 'job not found' }), 404
        if job.status in ('success','error','cancelled'):
            return jsonify({ 'cancelled': True })
        job.cancelled = True
    return jsonify({ 'cancelled': True })

@bp.get('/<job_id>')
def get_job(job_id):
    with lock:
        job = jobs.get(job_id)
        if not job:
            return jsonify({ 'message': 'job not found' }), 404
        return jsonify({
            'jobId': job.job_id,
            'modelId': job.model_id,
            'status': job.status,
            'total': job.total,
            'processed': job.processed,
            'inputType': job.input_type,
            'randomSeed': job.random_seed,
            'startedAt': job.started_at,
            'finishedAt': job.finished_at,
            'error': job.error
        })
```

---

## 7. 验收与联调步骤

1) 启动后端（开发）：
- 安装：`Flask`, `flask-cors`, `gunicorn`（可选）
- 运行：`FLASK_APP=backend.app flask run -p 5000`

2) Postman/curl 验证：
- 启动任务：
  ```bash
  curl -X POST http://localhost:5000/api/model-tests \
    -H 'Content-Type: application/json' \
    -d '{"modelId":1, "sampleCount":10, "randomSeed":42, "inputType":"image"}'
  ```
- 订阅 SSE：
  ```bash
  curl -N http://localhost:5000/api/model-tests/<jobId>/stream
  ```
- 取消任务：
  ```bash
  curl -X POST http://localhost:5000/api/model-tests/<jobId>/cancel
  ```

3) 前端联调：将 `src/api/test.js` 的实现替换为实际 API 调用，保持事件名称与字段一致。

---

## 8. 扩展与生产化建议

- 推理接入：将生成器替换为真实样本与推理调用（保证输出结构不变）
- 队列化：使用 Celery/RQ 解耦推理与 Web，Redis 用于共享状态与重放缓冲
- 资源管理：并发控制、GPU/CPU 资源池、任务配额
- 观测性：Prometheus 指标、结构化日志、请求链路追踪
- 高可用：多实例 + 共享状态（Redis/数据库），前置 Nginx 关闭缓冲
